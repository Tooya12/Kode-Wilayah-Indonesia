{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permendagri 72/2019 data structured data extraction\n",
    "\n",
    "Permendagri 72/2019 is a ministerial decree that is the latest edition (as of 2021) of Indonesia's administrative region codes.\n",
    "\n",
    "The raw dataset is a single 27MB PDF which consists of:\n",
    "* The ministerial decree itself\n",
    "* An appendix which contains the region codes (this is where the data will be extracted from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path\n",
    "input_path = './raw.pdf'\n",
    "output_path = './dist/base.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding relevant tables from the appendix\n",
    "\n",
    "The appendix is split into provinces. For each province has pages for:\n",
    "1. Kabupaten-level summary\n",
    "2. Details up to each desa, including deprecations\n",
    "3. Kecamatan-level summary\n",
    "\n",
    "We are only interested in (2). We need to find the ranges of pages which contain these relevant tables.\n",
    "\n",
    "To do this, we will use `pdftotext`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdftotext\n",
    "\n",
    "def find_relevant_pages(path_to_pdf):\n",
    "    with open(path_to_pdf, 'rb') as f:\n",
    "        pdf = pdftotext.PDF(f)\n",
    "\n",
    "        i = 1\n",
    "        ranges = []\n",
    "        temp = 0\n",
    "\n",
    "        for page in pdf:\n",
    "            if 'b. Kode Dan Data Wilayah Administrasi' in page:\n",
    "                temp = i\n",
    "            elif 'c. Rekapitulasi' in page and temp != 0:\n",
    "                ranges.append(range(temp, i))\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        return ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_ranges = find_relevant_pages(input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting tables into DataFrames\n",
    "\n",
    "We use `tabula` to extract tables from all relevant pages into DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabula import read_pdf\n",
    "\n",
    "AREA_HEAD = [142, 36, 568, 602]\n",
    "AREA_TAIL = [90, 35, 568, 601]\n",
    "\n",
    "def extract_tables(input_path, pages):\n",
    "    pages = list(pages)\n",
    "    page_head = pages[0]\n",
    "    pages_tail = pages[1:]\n",
    "\n",
    "\n",
    "    tabula_args = {\n",
    "        'silent': True,\n",
    "        'lattice': True,\n",
    "        'pandas_options': {\n",
    "            'header': None,\n",
    "            'dtype': 'string' # empty cells will be pandas.NA\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # The first frame uses a different area than the rest\n",
    "    head_frames = read_pdf(input_path,\n",
    "                           area=AREA_HEAD,\n",
    "                           pages=[page_head],\n",
    "                           **tabula_args)\n",
    "\n",
    "    tail_frames = read_pdf(input_path,\n",
    "                           area=AREA_TAIL,\n",
    "                           pages=pages_tail,\n",
    "                           **tabula_args)\n",
    "\n",
    "    return head_frames + tail_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_pages = []\n",
    "\n",
    "for relevant_range in relevant_ranges:\n",
    "    relevant_pages.extend(list(relevant_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = extract_tables(input_path, relevant_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing each DataFrame\n",
    "\n",
    "From each DataFrame, we can scrape the Code and a Raw Name. This Raw Name will be sanitised later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import isna\n",
    "import re\n",
    "\n",
    "def is_code(txt):\n",
    "    return re.match('^[0-9]{2}(\\.[0-9]{2}(\\.[0-9]{2}(\\.[1-2][0-9]{3})?)?)?$', str(txt))\n",
    "\n",
    "def parse_frame(frame):\n",
    "    output = []\n",
    "\n",
    "    # parse each row in the dataframe as a list    \n",
    "    for row in frame.values:\n",
    "        cells = [cell for cell in list(row) if not isna(cell)]\n",
    "        if len(cells) >= 2 and is_code(cells[0]) and type(cells[1]) == str:\n",
    "            code = cells[0]\n",
    "            raw_name = cells[1]\n",
    "            output.append((code, raw_name))\n",
    "\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's parse all of the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_to_raw_name = []\n",
    "\n",
    "for frame in frames:\n",
    "    tuples = parse_frame(frame)\n",
    "    code_to_raw_name.extend(tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we come up with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91220\n"
     ]
    }
   ],
   "source": [
    "print(len(code_to_raw_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanitising names\n",
    "\n",
    "Two things to sanitise:\n",
    "\n",
    "1. An ordinal number prefixing the name â€“ but some regions have actual numbers in the beginning of their names!\n",
    "2. Carriage returns (`\\r`) in the middle of a names\n",
    "3. Unnecessary in-padded strings such as `P A P U A`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_kec = 0\n",
    "counter_kel = 0\n",
    "counter_des = 0\n",
    "\n",
    "def parse_code(code):\n",
    "    global counter_kec, counter_kel, counter_des\n",
    "    if len(code) == 2: # provinsi\n",
    "        counter_kec = 0\n",
    "        counter_kel = 0\n",
    "        counter_des = 0\n",
    "        return '', 'provinsi'\n",
    "    elif len(code) == 5: # kab/kota\n",
    "        counter_kec = 0\n",
    "        counter_kel = 0\n",
    "        counter_des = 0\n",
    "        return '', 'kabkota'\n",
    "    elif len(code) == 8: # kecamatan\n",
    "        counter_kec += 1\n",
    "        counter_kel = 0\n",
    "        counter_des = 0\n",
    "        return str(counter_kec), 'kecamatan'\n",
    "    elif len(code) == 13:\n",
    "        if code[9] == '1': # kelurahan\n",
    "            counter_kel += 1\n",
    "            return str(counter_kel), 'kelurahan'\n",
    "        elif code[9] == '2':\n",
    "            counter_des += 1\n",
    "            return str(counter_des), 'desa'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "csv_output = []\n",
    "\n",
    "for row in code_to_raw_name:\n",
    "    code, raw_name = row\n",
    "    code = str(code)\n",
    "    ctr, ctx = parse_code(code)\n",
    "    name = raw_name\n",
    "\n",
    "    if ctx == 'provinsi':\n",
    "        name = raw_name.replace('\\r', '')\n",
    "    elif ctx == 'kabkota':\n",
    "        name = raw_name.replace('\\r', '')\n",
    "        name = re.sub('[0-9]+', '', name)\n",
    "        name = name.strip()\n",
    "    elif re.search('\\r' + ctr, raw_name):\n",
    "        name = re.sub('\\r(' + ctr + ')?', '', name)\n",
    "    else:\n",
    "        name = re.sub('^[0-9]+\\s+', '', name)\n",
    "        name = name.replace('\\r', '')\n",
    "\n",
    "    # sanitise cases like `P A P U A`\n",
    "    if re.search('^([A-Za-z] )+[A-Za-z]$', name):\n",
    "        name = re.sub('\\s', '', name)\n",
    "\n",
    "    # sanitise \" which should be '\n",
    "    name = name.replace('\"', \"'\")\n",
    "\n",
    "    csv_output.append((code, name, raw_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('64.07.05', 'Long Iram', 'Long Iram\\r1')\n"
     ]
    }
   ],
   "source": [
    "print(repr(csv_output[67536]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'done' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0e93333bdc63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'done' is not defined"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open(output_path, 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in csv_output:\n",
    "        a, b, _ = row\n",
    "        writer.writerow([a, b])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the area parameter for running tabula. Values are from Preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90, 35, 568, 601]\n"
     ]
    }
   ],
   "source": [
    "left = 35\n",
    "top = 90\n",
    "width = 566\n",
    "height = 478\n",
    "\n",
    "y1 = top\n",
    "x1 = left\n",
    "y2 = top + height\n",
    "x2 = left + width\n",
    "\n",
    "coordinates = [y1,x1,y2,x2]\n",
    "\n",
    "print(coordinates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}